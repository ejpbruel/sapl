\section{Optimizations}\label{sapljs:sec:optimizations}
Above we described a straightforward compilation scheme for \Sapl to \JS, where function calls (closures) are transformed to arrays.
The only optimization we already made is replacing arithmetic expressions directly by there \JS counterparts 
and thereby forcing the evaluation of there arguments. 
In this way we may impose unwanted eager sub-expressions into a program. 
If a programmer does not want this he or she should use an indirection via an own-made auxiliary function.

The \textsf{eval} functions is used to turn a closure into a real \JS function call and reduces a closure to head-normal-form.
The \textsf{eval} functions has to do a case analysis on the structure of the closure expression.
A closure expression can either be a primitive value (integer, boolean, string), a boxed value, a constructor value or a real function application closure.
For the last case we measured that a direct \JS call is about 15 times faster than making the same call using the 
\textsf{Sapl.eval} function on the closure representing the call. This overhead is significant. 
Fortunately, in many cases we can do an analysis at compile time and replace a call of \textsf{eval} for a closure by the corresponding hard coded \JS.
This transformation replaces:
\begin{verbatim}
Sapl.eval([f,[a1,..,an])
\end{verbatim}
by:
\begin{verbatim}
f(a1,..,an)
\end{verbatim}
This may only be done if \textsf{f} is a known function (thus not a variable) and the number of applied arguments matches the
number of arguments of \textsf{f}.
This can be done at every place where an explicit \textsf{eval} call is done:
\begin{itemize}
\item The first argument of a \textsf{select} or \textsf{if}.
\item The arguments of an arithmetic operation.
\end{itemize}
But also at every place where a result is returned, because \textsf{eval} is called for this result immediately.


Examples

\subsection{Normal Forms}
A major source of overhead in the current implementation are the calls to the
evaluator function {\texttt eval}, generated by applying the translation scheme
$T$ to built-in operators. To illustrate this, consider the following definition
of the fibonacci function, $fib$, in SAPL:

\begin{CleanCode}
fib = \ n -> n < 2 ? 1 : fib (n - 1) + fib (n - 2)
\end{CleanCode}

Applying $T$ to this expression yields the following code in JavaScript:

\begin{CleanCode}
var fib = function (n) {
    return n < 2 ? 1 : eval([fib, [eval(n) - 1]]) + eval([fib, [eval(n) - 2]]);
}
\end{CleanCode}

Using this definition, the number of calls to {\texttt eval} is proportional to
$O(n^2)$, which is prohibitive even for small values of $n$.


In the above example, two thunks are created for the recursive applications of
$fib$, only to be immediately reduced again to normal form because their value
is required by the operator $+$. It should be obvious that these applications
might as well be performed immediately in this case, thus avoiding both the
construction of the thunks and the outer two calls to {\texttt eval}. In
general, $T$ generates a call to {\texttt eval} when an expression is required
to be in normal form (for instance because it is used as an operand to a
built-in operator). However, if it is known at compile time that an expression
already is in normal form, the call to {\texttt eval} is unnecessary, and can
be avoided.

To take advantage of this observation, a new translation scheme, $S$, is
introduced, which is equivalent to $T$, except for the added restriction that
expressions generated by $S$ should always be in normal form. To adhere to this
restriction, the rule for function applications has to be rewritten as follows:

\begin{equation*}
S \llbracket E_1 \: E_2 \: \ldots \: E_n \rrbracket \equiv
\begin{cases}
[T \llbracket E_1 \rrbracket, [T \llbracket E_2 \rrbracket,
                               \ldots,
                               S \llbracket E_n \rrbracket]] &
        \text{if $n \le m$} \\
T \llbracket E_1 \rrbracket(T \llbracket E_2 \rrbracket,
                            \ldots,
                            T \llbracket E_n \rrbracket) &
        \text{if $n = m$} \\
eval([ T \llbracket E_1 \rrbracket(T \llbracket E_2 \rrbracket,
                                   \ldots,
                                   T \llbracket E_n \rrbracket),
                        [T \llbracket E_{m+1} \rrbracket,
                         \ldots,
                         T \llbracket E_n \rrbracket]]) &
        \text{otherwise (if $n > m$)}
\end{cases}
\end{equation*}
where $m$ is the arity of $E_1$.

The above rule assumes that $E_1$ is a lambda abstraction, and that the arity of
$E_1$ is known. The possibility that $E_1$ is actually an identifier introduces
the need for a symbol table, which allows names to be resolved to their
corresponding bindings. Furthermore, it is impossible to determine the arity of
a function at compile time in the following to the cases:

\begin{enumerate}
\item The function was passed as an argument to the current function
\item The function was returned as a the result of a function application
\end{enumerate}

In both cases, a call to {\texttt eval} is still necessary. The former case
occurs when $n > m$, and is already handled in the above rule. The latter case
occurs when $E_1$ is resolved to be a local identifier, and is handled by the
following additional rule:

\[ S \llbracket E_1 \: E_2 \: \ldots \: E_n \rrbracket \equiv
   eval(T \llbracket E_1 \: E_2 \: \ldots \: E_n \rrbracket) \]

Note how the behavior of $S$ closely mimics that of {\texttt eval}. Indeed,
from a conceptual point of view, $S$ performs the call to {\texttt eval} at
compile time, rather than run time. This allows the rule in $T$ for translating
built-in operators to be rewritten as follows:

\begin{align*}
T \llbracket op_1 \: E_1 \rrbracket &
        \equiv op_1 \: S \llbracket E_1 \rrbracket \\
T \llbracket E_1 \: op_2 \: E_2 \rrbracket &
        \equiv S \llbracket E_1 \rrbracket \: op_2 \:
               S \llbracket E_2 \rrbracket \\
T \llbracket E_1 \: ? \: E_2 \: : \: \rrbracket &
        \equiv S \llbracket E_1 \rrbracket \: ? \:
               S \llbracket E_2 \rrbracket \: : \:
               S \llbracket E_3 \rrbracket 
\end{align*}

Observe that this new rule does not generate any calls to {\texttt eval}, and
that $S$ only generates calls to {\texttt eval} if the arity of a function
cannot be determined at compile time.

In the above discussion, it was silently assumed that the result of a function
application is always in head normal form. To meet this requirement, however,
the rules for translating let(rec)-expressions and functions have to be
rewritten such that the expression returned is translated using $S$, rather than
$T$.

\subsection{Strictness Annotations}
By applying the optimization described in the previous section, the definition
of $fib$ can be reduced to:

\begin{CleanCode}
var fib = function (n) {
    return n < 2 ? 1 : fib(eval(n) - 1) + fib(eval(n) - 2)
}
\end{CleanCode}

Unfortunately, using this definition, the number of calls to {\texttt eval} is
still proportional to $O(n^2)$, which is prohibitive for anything but small
values of $n$. The remaining calls to {\texttt eval} are the result of SAPL's
use of lazy evaluation for function application. This makes it impossible for
the compiler to tell whether the argument $n$ will be in normal form at the time
that it is applied to $fib$, necessistating a call to {\texttt eval}.

In many cases, using eager rather than lazy evaluation can lead to much more
efficient code. For instance, using eager evaluation, the definition of $fib$
could have been further reduced to:

\begin{CleanCode}
var fib = function (n) {
    return n < 2 ? 1 : fib(n - 1) + fib(n - 2)
}
\end{CleanCode}

The calls to {\texttt eval} are now gone, which is a huge improvement. Indeed,
this is how $fib$ would have been written, had it been defined in JavaScript
directly. In this particular example, the use of eager evaluation did not affect
the semantics of the function. However, this is not true in general. As an
example of a function which semantics depend on the evaluation strategy used,
consider the following definition of the function $nats$ in SAPL:

\begin{CleanCode}
nats = \n -> cons 1 (nats (n + 1))
\end{CleanCode}

Using eager evaluation, the definition of $nats$ would have been reduced to:

\begin{CleanCode}
var nats = function (n) {
    return [cons [1, nats(n + 1)]];
}
\end{CleanCode}

leading to infinite recursion.

In general, the use of eager evaluation for an argument $x$ of a function $f$
does not affect the semantics of a $f$ if $f$ is strict in $x$. Assuming that it
is known at compile time in which arguments a function is strict, this suggests
the use of following optimization rule:

\begin{quote}
Use eager evaluation if an argument is strict; use lazy evaluation otherwise
\end{quote}

Using this rule, the code generator can avoid generating calls to {\texttt eval}
for strict arguments, because it can guarantee that these are in normal form
when the function is applied. The problem of determining in which arguments a
function is strict is offloaded to the offline compiler, which adds so-called
{\em strictness annotations} to the arguments of lambda abstractions as a hint
to the online compiler. Performing strictness analysis offline has the
additional advantage that we can use more sophisticated algorithms, which rely
on the use of type information to guarantee efficiency.

A potential problem with the above approach is that, as with determining the
arity, is is impossible to determine strictness information for a function $f$
that is passed as an argument or returned as a result. The naive solution of
assuming that the $f$ is non-strict in all its arguments will not work in this
case, because the compiler must be able to guarantee that strict arguments are
in normal form. One possible solution to this problem is to wrap $f$ into
another function $f'$, that is non-strict in all its arguments, and evaluates
the appropriate arguments before making the call to $f$. In the case of $fib$,
this wrapper function looks something like this:

\begin{CleanCode}
var fib = function (n) {
    return function (n) {
        return n < 2 ? (n - 1) : fib (n - 1) + fib (n - 2)
    }(eval(n));
}
\end{CleanCode}

It should be stretched though, that this wrapper function is only generated
in-place when it is required, so the overhead of the additional function call
is only occured when this is necessary.

\section{Alternative Optimizations}\label{sapljs:sec:optimizations}
INTRODUCTIONARY REMARKS

\subsection{Strictness Annotations}
By applying the optimization described in the previous section, the definition
of $fib$ can be reduced to:

\begin{CleanCode}
var fib = function (n) {
    return n < 2 ? 1 : fib(eval(n) - 1) + fib(eval(n) - 2)
}
\end{CleanCode}

Unfortunately, using this definition, the number of calls to {\texttt eval} is
still proportional to $O(n^2)$, which is prohibitive for anything but small
values of $n$. The remaining calls to {\texttt eval} are the result of SAPL's
use of lazy evaluation for function application. This makes it impossible for
the compiler to tell whether the argument $n$ will be in normal form at the time
that it is applied to $fib$, necessistating a call to {\texttt eval}.

In many cases, using eager rather than lazy evaluation can lead to much more
efficient code. For instance, using eager evaluation, the definition of $fib$
could have been further reduced to:

\begin{CleanCode}
var fib = function (n) {
    return n < 2 ? 1 : fib(n - 1) + fib(n - 2)
}
\end{CleanCode}

The calls to {\texttt eval} are now gone, which is a huge improvement. Indeed,
this is how $fib$ would have been written, had it been defined in JavaScript
directly. In this particular example, the use of eager evaluation did not affect
the semantics of the function. However, this is not true in general. As an
example of a function which semantics depend on the evaluation strategy used,
consider the following definition of the function $nats$ in SAPL:

\begin{CleanCode}
nats = \n -> cons 1 (nats (n + 1))
\end{CleanCode}

Using eager evaluation, the definition of $nats$ would have been reduced to:

\begin{CleanCode}
var nats = function (n) {
    return [cons [1, nats(n + 1)]];
}
\end{CleanCode}

leading to infinite recursion.

In general, the use of eager evaluation for an argument $x$ of a function $f$
does not affect the semantics of a $f$ if $f$ is strict in $x$. Assuming that it
is known at compile time in which arguments a function is strict, this suggests
the use of following optimization rule:

\begin{quote}
Use eager evaluation if an argument is strict; use lazy evaluation otherwise
\end{quote}

Using this rule, the code generator can avoid generating calls to {\texttt eval}
for strict arguments, because it can guarantee that these are in normal form
when the function is applied. The problem of determining in which arguments a
function is strict is offloaded to the offline compiler, which adds so-called
{\em strictness annotations} to the arguments of lambda abstractions as a hint
to the online compiler. Performing strictness analysis offline has the
additional advantage that we can use more sophisticated algorithms, which rely
on the use of type information to guarantee efficiency.

A potential problem with the above approach is that, as with determining the
arity, is is impossible to determine strictness information for a function $f$
that is passed as an argument or returned as a result. The naive solution of
assuming that the $f$ is non-strict in all its arguments will not work in this
case, because the compiler must be able to guarantee that strict arguments are
in normal form. One possible solution to this problem is to wrap $f$ into
another function $f'$, that is non-strict in all its arguments, and evaluates
the appropriate arguments before making the call to $f$. In the case of $fib$,
this wrapper function looks something like this:

\begin{CleanCode}
var fib = function (n) {
    return function (n) {
        return n < 2 ? (n - 1) : fib (n - 1) + fib (n - 2)
    }(eval(n));
}
\end{CleanCode}

It should be stretched though, that this wrapper function is only generated
in-place when it is required, so the overhead of the additional function call
is only occured when this is necessary.
